<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-upper" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Upper triangular matrices</title>

  <introduction>
    <p> In this section, we will use our understanding of the minimal
    polynomial to find some standard forms for matrices of operators.
    First, we will consider upper triangular matrices.
    </p>
  </introduction>
  
    <p>As we have seen in the past, upper triangular matrices have
    some simple properties.  For one, the eigenvalues of the
    associated operator equal the diagonal elements of the matrix.  We
    have also seen that linear systems formed by triangular matrices
    are relatively easy to solve.  All told, they form a pleasant set
    of matrices.
    </p>

    <p>Remember that an upper triangular matrix is one whose entries
    are zero below the diagonal;  that is, they have a form like this:
    <me>
      \begin{bmatrix}
      * \amp * \amp \ldots \amp * \amp * \\
      0 \amp * \amp \ldots \amp * \amp * \\
      \vdots \amp 0 \amp \ddots \amp * \amp * \\
      0 \amp 0 \amp \ldots \amp 0 \amp * \\
      \end{bmatrix}
    </me>.
    Suppose that <m>T</m> is an operator and that there is a basis
    <m>\vvec_1,\vvec_2,\ldots,\vvec_n</m> for which the associated
    matrix <m>A</m> for <m>T</m> is upper triangular.  Since
    <m>A_{k,j} = 0</m> if <m>k \gt j</m>, we have
    <mdn>
      <mrow xml:id="me-upper-triang-1">
        T\vvec_1 \amp = A_{1,1}\vvec_1
      </mrow>
      <mrow xml:id="me-upper-triang-2">
        T\vvec_2 \amp = A_{1,2}\vvec_1 + A_{2,2}\vvec_2
      </mrow>
      <mrow>
        T\vvec_3 \amp = A_{1,3}\vvec_1 + A_{2,3}\vvec_2 + A_{3,3}\vvec_3
      </mrow>
    </mdn>
    and so forth.
    </p>

    <p>
    Notice that <xref ref="me-upper-triang-1"/> says that <m>T\vvec_1
    = A_{1,1}\vvec_1</m> so
    that <m>\vvec_1</m> is an eigenvector with associated eigenvalue
    <m>A_{1,1}</m>.
    </p>

    <p>In addition, <xref ref="me-upper-triang-2"/> tells us that
    <me>
      T\vvec_2 = A_{2,1}\vvec_1 + A_{2,2}\vvec_2
    </me>,
    which implies that <m>\laspan{\vvec_1,\vvec_2}</m> is invariant
    under <m>T</m>.
    </p>

    <p>More generally,
    <me>
      T\vvec_j = A_{j,1}\vvec_1 + A_{j,2}\vvec_2 + \ldots +
      A_{k,k}\vvec_k
    </me>,
    which says that, for every <m>j</m>,
    <m>\laspan{\vvec_1,\vvec_2,\ldots,\vvec_j}</m> is 
    invariant under <m>T</m>.
    </p>

    <p>Let's record this as a proposition.
    </p>

    <proposition xml:id="prop-upper-invariant">
      <statement>
	<p>Suppose that <m>T</m> is an operator on the vector space
	<m>V</m>.  Then there is a basis
	<m>\vvec_1,\vvec_2,\ldots,\vvec_n</m> for <m>V</m> in which
	the associated matrix of <m>T</m> is upper triangular if and
	only if <m>\laspan{\vvec_1,\vvec_2,\ldots,\vvec_j}</m> is
	invariant under <m>T</m> for each <m>j</m>.
	</p>
      </statement>
      <proof>
	<p>The discussion above explains why an operator with an upper
	triangular matrix forms invariant subspaces.  Conversely,
	suppose that <m>\laspan{\vvec_1,\vvec_2,\ldots,\vvec_j}</m> is
	invariant for every <m>j</m>.  The matrix <m>A</m> associated
	to <m>T</m> satisfies
	<me>
	  T\vvec_j = \sum_{k=1}^n A_{k,j}\vvec_k =
	  \sum_{k=1}^jA_{k,j}\vvec_k
	</me>,
	which shows that <m>A_{k,j}=0</m> if <m>k\gt j</m> and that
	<m>A</m> is therefore upper triangular.
	</p>
      </proof>
    </proposition>

    <p>We can rephrase this in terms of polynomials.</p>

    <proposition xml:id="prop-upper-min">
      <statement>
	<p>Suppose that <m>T</m> is an operator on <m>V</m> and that
	there is a basis <m>\vvec_1,\vvec_2,\ldots,\vvec_n</m> of
	<m>V</m> such that the matrix <m>A</m> of <m>T</m> is upper
	triangular.  Then
	<me>
	  (T-A_{1,1}I)
	  (T-A_{2,2}I)
	  \ldots
	  (T-A_{n,n}I) = 0
	</me>.
	</p>
      </statement>
      <proof>
	<p> We will use <m>q</m> to denote the polynomial
	<me>
	  q(x)=(x-A_{1,1})(x-A_{2,2})\ldots(x-A_{n,n})
	</me>.
	</p>

	<p>First consider <m>\vvec_1</m>.  Since <m>A</m> is upper
	triangular, we know that <m>T\vvec_1=A_{1,1}\vvec_1</m>, which
	means that <m>(T-A_{1,1}I)\vvec_1 = 0</m>.  Therefore,
	<m>q(T)\vvec_1 = 0</m>.
	</p>

	<p>Next consider <m>\vvec_2</m> for <m>T\vvec_2 =
	A_{1,2}\vvec_1 + A_{2,2}\vvec_2</m>.  Rearranging gives
	<me>
	  (T-A_{2,2}I)\vvec_2 = A_{1,2}\vvec_1
	</me>.
	Therefore,
	<me>
	  (T-A_{1,1}I)(T-A_{2,2}I)\vvec_2 = A_{1,2}(T-A_{1,1}I)\vvec_1 = 0
	</me>,
	which tells us that <m>q(T)\vvec_2=0</m>.
	</p>

	<p>Continuing in this way, we see that
	<me>
	  (T-A_{1,1}I)(T-A_{2,2}I)\ldots (T-A_{j,j}I)\vvec_j = 0
	</me>
	and hence that <m>q(T)\vvec_j=0</m>.  This means that
	<m>q(T)\vvec=0</m> for every vector <m>\vvec</m> and so we
	know that <m>q(T)=0</m> as claimed.
	</p>
      </proof>
    </proposition>

    <p>This leads to the following crucial result.
    </p>

    <theorem xml:id="thm-upper-minimal">
      <statement>
	<p>Suppose that <m>T</m> is an operator on <m>V</m> over the
	field <m>\field</m>.  There is
	a basis for <m>V</m> for which the matrix of <m>T</m> is upper
	triangular if and only if the minimal polynomial of <m>T</m>
	has the form
	<me>
	  p(x) = (x-\lambda_1)(x-\lambda_2)\ldots(x-\lambda_m)
	</me>
	where the roots <m>\lambda_j</m> are in <m>\field</m>.
	</p>
        <p>Moreover, when this happens, the diagonal entries of the
        matrix are the eigenvalues of <m>T</m>. 
        </p>
      </statement>

      <proof>
	<p>One direction is a natural consequence of <xref
	ref="prop-upper-min"/>.  Suppose that there is a basis for
	which the matrix <m>A</m> of <m>T</m> is upper triangular.  That
	proposition tells us that <m>q(T) = 0</m> for
	<me>
	  q(x)=(x-A_{1,1})(x-A_{2,2})\ldots(x-A_{n,n})
	</me>.
	Since <m>q(T) = 0</m>,
        <xref ref="prop-min-poly-div"/> tells us that <m>q</m> is a
        multiple of
	the minimal polynomial of <m>T</m>, which says that the
	minimal polynomial has the form given in the statement of this
	theorem.  Because the eigenvalues are the roots of the minimal
        polynomial, we also know that the diagonal entries of the
        matrix are the eigenvalues.
	</p>

	<p>Now suppose that the minimal polynomial <m>p</m> has the
	form given.  We will prove by induction that there is a basis
	for which the matrix of <m>T</m> is upper triangular.
	</p>

	<p>First suppose that <m>m=1</m> so that <m>T-\lambda_1I =
	0</m>.  This means that <m>T=\lambda_1 I</m> so that the
	matrix of <m>T</m> in any basis is diagonal and hence upper
	triangular.  Notice that the diagonal entries of this matrix
        are <m>\lambda_1</m>, which is an eigenvalue of <m>T</m>.
	</p>

	<p>Let's now suppose that the result is true for any operator
	and vector space for which the minimal polynomial has the form
	<me>
	  p(x) = (x-\lambda_1)(x-\lambda_2)\ldots(x-\lambda_k)
	</me>
	where <m>k\lt m</m>.  Consider the subspace
	<m>W=\range(T-\lambda_mI)</m>, which we know is invariant under
	<m>T</m>.  Since any vector <m>\wvec</m> in <m>W</m> has the
	form <m>\wvec = (T-\lambda_mI)\uvec</m>, we know that
	<me>
	  (T-\lambda_1I)(T-\lambda_2I)\ldots(T-\lambda_{m-1}I)\wvec = \zerovec
	</me>. 
	Therefore, if
	<me>q(x)=
	(x-\lambda_1)(x-\lambda_2)\ldots(x-\lambda_{m-1})
	</me>,
	then <m>q(T|_W) = 0</m>.  As a result, <m>q</m> is a multiple
	of the minimal polynomial of <m>T|_W</m> and so the minimal
	polynomial of <m>T|_W</m> is a product of fewer than <m>m</m>
	terms having the form <m>x-\alpha_j</m>.  By the induction
	hypothesis, we know there is a basis
	<m>\wvec_1,\wvec_2,\ldots,\wvec_k</m> for <m>W</m> so that the
	basis of <m>T|_W</m> is upper triangular.
	</p>

	<p>We will now extend the basis of <m>W</m> by vectors
	<m>\vvec_1,\vvec_2,\ldots,\vvec_{n-k}</m>.  Since
	<m>T\vvec_j</m> is in <m>W</m>, we have
	<me>
	  T\vvec_j = (T-\lambda_mI)\vvec_j + \lambda_m\vvec_j
	</me>
	or
	<me>
	  T\vvec_j = A_{j,k}\wvec_k + \lambda_m\vvec_j
	</me>,
	which shows that the matrix of <m>T</m> is upper triangular.
        Furthermore, the diagonal entry of the matrix associated to
        <m>\vvec_j</m> is <m>\lambda_m</m>, which shows that the
        diagonal entries of the matrix are the eigenvalues of <m>T</m>.
	</p>
      </proof>
    </theorem>

    <p>Notice that the
    <xref ref="thm-fta"
          text="custom">
      Fundamental Theorem of
      Algebra"
    </xref>
    tells us that any polynomial with complex
    coefficients has the form given in <xref
    ref="thm-upper-minimal"/>.  As a result, any operator on a complex
    vector space <m>V</m> has a basis for which the associated matrix
    is upper triangular. 
    </p>

    <proposition xml:id="prop-complex-upper">
      <statement>
        <p>If <m>T</m> is an operator on a finite dimensional complex
        vector space <m>V</m>, then there is a basis <m>\bcal</m> for
        <m>V</m> such that <m>\coords{T}{\bcal}</m> is upper
        triangular.
        </p>
      </statement>
    </proposition>

    <example>
      <statement>
        <p>Let's consider the operator <m>T:\real^3\to\real^3</m>
        defined by the matrix <m>A=\begin{bmatrix}
        2 \amp 8 \amp 8 \\
        6 \amp 3 \amp 9 \\
        10 \amp 7 \amp 1
        \end{bmatrix}</m>.  The minimal polynomial of <m>T</m> is
        <me>
          p(x)=(x-18)(x+6)^2
        </me>,
        which satisfies the hypothesis of <xref
        ref="thm-upper-minimal"/>.  Therefore, there is a basis
        <m>\bcal</m> so that
        <m>\coords{T}{\bcal}</m> is upper triangular.  We will find
        such a basis following
        the proof of the theorem.
        </p>

        <p>Consider one factor <m>x+6</m> of the minimal polynomial of
        <m>T</m> and construct <m>U_1 = \range(T+6I)</m>.  We see that
        <me>
          A + 6I =
          \begin{bmatrix}
          8 \amp 8 \amp 8 \\
          6 \amp 9 \amp 9 \\
          10 \amp 7 \amp 7
          \end{bmatrix}
          \sim
          \begin{bmatrix}
          1 \amp 0 \amp 0 \\
          0 \amp 1 \amp 1 \\
          0 \amp 0 \amp 0 \\
          \end{bmatrix}
        </me>.
        This shows that a basis for <m>U_1</m> consists
        of the vectors
        <me>
          \uvec_1 = \threevec86{10},\hspace{12pt}
          \uvec_2 = \threevec89{7}
        </me>.
        We have
        <md>
          <mrow>
            T\uvec_1 \amp = 2\uvec_1 + 16\uvec_2
          </mrow>
          <mrow>
            T\uvec_2 \amp = 8\uvec_1 + 10\uvec_2
          </mrow>
        </md>
        so that the matrix <m>\begin{bmatrix}2 \amp 8 \\ 16 \amp 10
        \end{bmatrix}</m> represents <m>T|_{U_1}</m> in this basis.
        </p>

        <p>Of course, we know that the minimal polynomial of
        <m>T|_{U_1}</m> is <m>(x-18)(x+6)</m> so we consider the
        operator <m>T|_{U_1}+6I</m> on <m>U_1</m>, which is
        represented by the 
        matrix
        <m>\begin{bmatrix}8 \amp 8 \\ 16 \amp 16 \end{bmatrix}</m> in
        this basis.  Therefore, a basis for
        <m>U_2 = \range(T|_{U_1}+6I)</m> is
        <me>
          \vvec_1 = 8\uvec_1 + 16\uvec_2 = \threevec{192}{192}{192}
        </me>.
        We note that <m>T\vvec_1 = 18\vvec_1</m>, as expected since
        the minimial polynomial of <m>T|_{U_2}</m> is <m>x-18</m>.
        </p>

        <p>We will now work our way back out to find a basis for
        <m>U_1=\laspan{\uvec_1,\uvec_2}</m>.  We have <m>\vvec_1 =
        8\uvec_1+16\uvec_2</m> so we will take <m>\vvec_2 =
        \uvec_1=\threevec86{10}</m>.  (There are lots of possible choices 
        since we just need to choose a vector in <m>U_1</m> that is not a
        scalar multiple of <m>\vvec_1</m>.)  Notice that
        <md>
          <mrow>
            T\vvec_1 \amp = 18\vvec_1
          </mrow>
          <mrow>
            T\vvec_2 \amp = \vvec_1 - 6\vvec_2
          </mrow>
        </md>.
        </p>

        <p>We just need to find a vector <m>\vvec_3</m> so that
        <m>\{\vvec_1,\vvec_2,\vvec_3\}</m> forms a basis for
        <m>\real^3</m>.  Again, there are lots of possibilities so we
        choose <m>\vvec_3 = \threevec100</m>.  We see that
        <md>
          <mrow>
            T\vvec_1 \amp = 18\vvec_1
          </mrow>
          <mrow>
            T\vvec_2 \amp = \vvec_1 - 6\vvec_2
          </mrow>
          <mrow>
            T\vvec_3 \amp = \vvec_2 - 6\vvec_3
          </mrow>
        </md>.
        </p>

        <p>If we call the basis
        <m>\bcal=\{\vvec_1,\vvec_2,\vvec_3\}</m>, then
        <me>
          B = \coords{T}{\bcal}=
          \begin{bmatrix}
          18 \amp 1 \amp 0 \\
          0 \amp -6 \amp 1 \\
          0 \amp 0 \amp -6 \\
          \end{bmatrix}
        </me>,
        which shows that we have found an upper triangular matrix
        representing <m>T</m>.
        </p>

        <p>Thinking in terms of matrices, we construct
        <me>
          P=\begin{bmatrix}\vvec_1 \amp \vvec_2 \amp \vvec_3
          \end{bmatrix}
          = \begin{bmatrix}
          192 \amp 8 \amp 1 \\
          192 \amp 6 \amp 0 \\
          192 \amp 10 \amp 0
          \end{bmatrix}
        </me>
        and find that our original matrix <m>A=PBP^{-1}</m>.  In other
        words, we have demonstrated that <m>A</m> is similar to an
        upper triangular matrix, as predicted by <xref
        ref="thm-upper-minimal"/>.
        </p>
      </statement>
    </example>

  </section>
